# æ·±åº¦å­¦ä¹ é¡¹ç›®æ–‡æ¡£æ¨¡æ¿

> é€‚ç”¨äºTransformerã€LSTM+CNNã€Autoencoderç­‰æ·±åº¦å­¦ä¹ é¡¹ç›®çš„é€šç”¨æ–‡æ¡£æ¨¡æ¿

## ğŸ“˜ ä½¿ç”¨è¯´æ˜

æœ¬æ¨¡æ¿æä¾›äº†å®Œæ•´çš„æ·±åº¦å­¦ä¹ é¡¹ç›®æ–‡æ¡£æ¡†æ¶ï¼ŒåŒ…å«ä¸‰ä¸ªä¸»è¦æ–‡æ¡£ï¼š
1. **README.md** - é¡¹ç›®ç®€ä»‹å’Œå¿«é€Ÿå¼€å§‹
2. **ç¯å¢ƒé…ç½®.md** - è¯¦ç»†çš„ç¯å¢ƒæ­å»ºæŒ‡å—
3. **ä½¿ç”¨æŒ‡å—.md** - å®Œæ•´çš„é¡¹ç›®ä½¿ç”¨æ–‡æ¡£

### å¦‚ä½•ä½¿ç”¨æœ¬æ¨¡æ¿

1. **å¤åˆ¶æ¨¡æ¿æ–‡ä»¶**åˆ°ä½ çš„é¡¹ç›®ä¸­
2. **æ›¿æ¢å ä½ç¬¦**ï¼šç”¨`[å®é™…å†…å®¹]`æ ‡è®°çš„éƒ¨åˆ†éœ€è¦æ›¿æ¢
3. **åˆ é™¤ä¸é€‚ç”¨çš„éƒ¨åˆ†**ï¼šæ ¹æ®é¡¹ç›®ç‰¹ç‚¹åˆ é™¤æˆ–ä¿®æ”¹
4. **å‚è€ƒç¤ºä¾‹**ï¼šæ¯ä¸ªéƒ¨åˆ†éƒ½æä¾›äº†é’ˆå¯¹ä¸åŒæ¨¡å‹çš„ç¤ºä¾‹

### å ä½ç¬¦è¯´æ˜

| å ä½ç¬¦ | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|
| `[é¡¹ç›®åç§°]` | ä½ çš„é¡¹ç›®åç§° | "åŸºäºTransformerçš„æ–‡æœ¬åˆ†ç±»ç³»ç»Ÿ" |
| `[æ¨¡å‹åç§°]` | æ¨¡å‹æ¶æ„åç§° | "Transformer", "LSTM+CNN", "Autoencoder" |
| `[ä»»åŠ¡ç±»å‹]` | ä»»åŠ¡ç±»å‹ | "åˆ†ç±»", "å›å½’", "ç”Ÿæˆ", "é™ç»´" |
| `[æ•°æ®ç±»å‹]` | è¾“å…¥æ•°æ®ç±»å‹ | "æ–‡æœ¬", "å›¾åƒ", "æ—¶é—´åºåˆ—", "è°±å›¾" |
| `[è¾“å…¥ç»´åº¦]` | è¾“å…¥æ•°æ®ç»´åº¦ | 512, (224, 224, 3), 1000 |
| `[è¾“å‡ºç»´åº¦]` | è¾“å‡ºç»´åº¦ | 10ç±», è¿ç»­å€¼, é‡æ„æ•°æ® |

---

## æ¨¡æ¿ä¸€ï¼šREADME.md

```markdown
# [é¡¹ç›®åç§°]

> [ä¸€å¥è¯é¡¹ç›®æè¿°]

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†åŸºäº[æ¨¡å‹åç§°]çš„[ä»»åŠ¡ç±»å‹]ç³»ç»Ÿï¼Œç”¨äº[å…·ä½“åº”ç”¨åœºæ™¯]ã€‚

**ä¸»è¦ç‰¹ç‚¹**ï¼š
- âœ… [ç‰¹ç‚¹1ï¼šå¦‚"æ³¨æ„åŠ›æœºåˆ¶"]
- âœ… [ç‰¹ç‚¹2ï¼šå¦‚"ç«¯åˆ°ç«¯è®­ç»ƒ"]
- âœ… [ç‰¹ç‚¹3ï¼šå¦‚"å¤šä»»åŠ¡å­¦ä¹ "]
- âœ… [ç‰¹ç‚¹4ï¼šå¦‚"å®Œæ•´çš„è®­ç»ƒå’Œæ¨ç†æµç¨‹"]
- âœ… [ç‰¹ç‚¹5ï¼šå¦‚"è¯¦ç»†çš„ä¸­æ–‡æ–‡æ¡£"]

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- **Python**: 3.8 - 3.11
- **æ“ä½œç³»ç»Ÿ**: Windows / Linux / macOS
- **å†…å­˜**: å»ºè®®[X]GBä»¥ä¸Š
- **GPU**: [å¯é€‰/å¿…éœ€]

### å®‰è£…æ­¥éª¤

**1. åˆ›å»ºç¯å¢ƒ**

\`\`\`bash
conda create -n [ç¯å¢ƒåç§°] python=3.11 -y
conda activate [ç¯å¢ƒåç§°]
\`\`\`

**2. å®‰è£…ä¾èµ–**

\`\`\`bash
pip install -r requirements.txt
\`\`\`

**3. å¿«é€Ÿæµ‹è¯•**

\`\`\`bash
python quick_start.py
\`\`\`

### ä½¿ç”¨ç¤ºä¾‹

\`\`\`bash
# è®­ç»ƒæ¨¡å‹
python train.py

# ä½¿ç”¨æ¨¡å‹
python predict.py

# [å…¶ä»–å‘½ä»¤]
python [å…¶ä»–è„šæœ¬].py
\`\`\`

## é¡¹ç›®ç»“æ„

\`\`\`
[é¡¹ç›®æ ¹ç›®å½•]/
â”œâ”€â”€ config.py              # é…ç½®æ–‡ä»¶
â”œâ”€â”€ train.py               # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ predict.py             # é¢„æµ‹è„šæœ¬
â”œâ”€â”€ quick_start.py         # å¿«é€Ÿæ¼”ç¤º
â”œâ”€â”€ models/                # æ¨¡å‹å®šä¹‰
â”œâ”€â”€ data/                  # æ•°æ®å¤„ç†
â”œâ”€â”€ utils/                 # å·¥å…·å‡½æ•°
â”œâ”€â”€ requirements.txt       # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ docs/                  # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ ç¯å¢ƒé…ç½®.md
â”‚   â””â”€â”€ ä½¿ç”¨æŒ‡å—.md
â””â”€â”€ README.md              # æœ¬æ–‡ä»¶
\`\`\`

## æ¨¡å‹æ€§èƒ½

| æ¨¡å‹ | [æŒ‡æ ‡1] | [æŒ‡æ ‡2] | [æŒ‡æ ‡3] | å‚æ•°é‡ |
|------|---------|---------|---------|--------|
| [æ¨¡å‹1] | [å€¼] | [å€¼] | [å€¼] | [X]M |
| [æ¨¡å‹2] | [å€¼] | [å€¼] | [å€¼] | [X]M |

*åŸºäº[æ•°æ®é›†åç§°]çš„æµ‹è¯•ç»“æœ*

## è¯¦ç»†æ–‡æ¡£

- ğŸ“– **[ç¯å¢ƒé…ç½®.md](docs/ç¯å¢ƒé…ç½®.md)** - è¯¦ç»†çš„ç¯å¢ƒæ­å»ºæŒ‡å—
- ğŸ“– **[ä½¿ç”¨æŒ‡å—.md](docs/ä½¿ç”¨æŒ‡å—.md)** - å®Œæ•´çš„é¡¹ç›®ä½¿ç”¨æ–‡æ¡£

## é€‚ç”¨åœºæ™¯

- [åº”ç”¨åœºæ™¯1]
- [åº”ç”¨åœºæ™¯2]
- [åº”ç”¨åœºæ™¯3]
- [åº”ç”¨åœºæ™¯4]

## æŠ€æœ¯æ ˆ

- **æ·±åº¦å­¦ä¹ æ¡†æ¶**: PyTorch [ç‰ˆæœ¬å·]
- **ä¸»è¦åº“**: [NumPy, Pandas, ç­‰]
- **å¯è§†åŒ–**: Matplotlib, [å…¶ä»–]
- **å…¶ä»–**: [å…¶ä»–é‡è¦åº“]

## è®¸å¯

[è®¸å¯è¯ç±»å‹ï¼Œå¦‚MIT, Apache 2.0ç­‰]

## è‡´è°¢

[è‡´è°¢å†…å®¹ï¼Œå¯é€‰]

## è”ç³»æ–¹å¼

[è”ç³»æ–¹å¼ï¼Œå¯é€‰]

---

**ç‰ˆæœ¬**: v[ç‰ˆæœ¬å·]  
**æ›´æ–°æ—¥æœŸ**: [æ—¥æœŸ]
\`\`\`

---

## æ¨¡æ¿äºŒï¼šç¯å¢ƒé…ç½®.md

```markdown
# ç¯å¢ƒé…ç½®æŒ‡å—

> æœ¬æŒ‡å—å¸®åŠ©æ‚¨ä»é›¶å¼€å§‹é…ç½®é¡¹ç›®è¿è¡Œç¯å¢ƒ

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [æ–¹å¼ä¸€ï¼šä½¿ç”¨Minicondaï¼ˆæ¨èï¼‰](#æ–¹å¼ä¸€ä½¿ç”¨minicondaæ¨è)
- [æ–¹å¼äºŒï¼šä½¿ç”¨ç³»ç»ŸPython](#æ–¹å¼äºŒä½¿ç”¨ç³»ç»Ÿpython)
- [éªŒè¯å®‰è£…](#éªŒè¯å®‰è£…)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚

- **å†…å­˜**: å»ºè®®[X]GBä»¥ä¸Š
- **ç¡¬ç›˜**: è‡³å°‘[X]GBå¯ç”¨ç©ºé—´
- **GPU**: [å¯é€‰/å¿…éœ€] - [GPUå‹å·è¦æ±‚]
- **å¤„ç†å™¨**: [å¤„ç†å™¨è¦æ±‚]

### è½¯ä»¶è¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: [æ”¯æŒçš„æ“ä½œç³»ç»Ÿ]
- **Pythonç‰ˆæœ¬**: 3.8 - 3.11
- **CUDAç‰ˆæœ¬**: [å¦‚æœéœ€è¦GPU] - CUDA [ç‰ˆæœ¬å·]

---

## æ–¹å¼ä¸€ï¼šä½¿ç”¨Minicondaï¼ˆæ¨èï¼‰

### æ­¥éª¤1ï¼šå®‰è£…Miniconda

**ä¸‹è½½åœ°å€**ï¼š
- æ¸…åé•œåƒï¼šhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/
- å®˜æ–¹åœ°å€ï¼šhttps://docs.conda.io/en/latest/miniconda.html

**é€‰æ‹©ç‰ˆæœ¬**ï¼š
- Windows: `Miniconda3-latest-Windows-x86_64.exe`
- Linux: `Miniconda3-latest-Linux-x86_64.sh`
- macOS: `Miniconda3-latest-MacOSX-x86_64.sh`

### æ­¥éª¤2ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

\`\`\`bash
# åˆ›å»ºç¯å¢ƒ
conda create -n [ç¯å¢ƒåç§°] python=3.11 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate [ç¯å¢ƒåç§°]
\`\`\`

### æ­¥éª¤3ï¼šé…ç½®é•œåƒæºï¼ˆå¯é€‰ï¼‰

\`\`\`bash
# æ·»åŠ æ¸…åé•œåƒ
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/

# é…ç½®pipé•œåƒ
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
\`\`\`

### æ­¥éª¤4ï¼šå®‰è£…ä¾èµ–

\`\`\`bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /d "[é¡¹ç›®è·¯å¾„]"

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
\`\`\`

**[å¦‚æœé¡¹ç›®éœ€è¦ç‰¹æ®Šçš„å®‰è£…æ­¥éª¤ï¼Œåœ¨æ­¤è¯´æ˜]**

ä¾‹å¦‚ï¼Œå¯¹äºéœ€è¦GPUçš„é¡¹ç›®ï¼š
\`\`\`bash
# å®‰è£…GPUç‰ˆæœ¬çš„PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
\`\`\`

---

## æ–¹å¼äºŒï¼šä½¿ç”¨ç³»ç»ŸPython

[ç®€åŒ–çš„å®‰è£…æ­¥éª¤ï¼Œé€‚ç”¨äºå·²æœ‰Pythonç¯å¢ƒçš„ç”¨æˆ·]

### æ­¥éª¤1ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

\`\`\`bash
python -m venv venv
\`\`\`

### æ­¥éª¤2ï¼šæ¿€æ´»ç¯å¢ƒ

**Windows**:
\`\`\`bash
venv\\Scripts\\activate
\`\`\`

**Linux/macOS**:
\`\`\`bash
source venv/bin/activate
\`\`\`

### æ­¥éª¤3ï¼šå®‰è£…ä¾èµ–

\`\`\`bash
pip install -r requirements.txt
\`\`\`

---

## éªŒè¯å®‰è£…

è¿è¡Œå¿«é€Ÿæµ‹è¯•ç¨‹åºï¼š

\`\`\`bash
python quick_start.py
\`\`\`

**é¢„æœŸè¾“å‡º**ï¼š
\`\`\`
[é¢„æœŸçš„è¾“å‡ºç¤ºä¾‹]
\`\`\`

### éªŒè¯å…³é”®åº“

\`\`\`bash
# éªŒè¯PyTorch
python -c "import torch; print('PyTorch:', torch.__version__)"

# [å…¶ä»–å…³é”®åº“éªŒè¯]
python -c "import [åº“å]; print('[åº“å]:', [åº“å].__version__)"

# [å¦‚æœä½¿ç”¨GPU] éªŒè¯CUDA
python -c "import torch; print('CUDAå¯ç”¨:', torch.cuda.is_available())"
\`\`\`

---

## å¸¸è§é—®é¢˜

### Q1: [å¸¸è§é—®é¢˜1]

**ç°è±¡**ï¼š
\`\`\`
[é”™è¯¯ä¿¡æ¯]
\`\`\`

**è§£å†³æ–¹æ¡ˆ**ï¼š
\`\`\`bash
[è§£å†³æ­¥éª¤]
\`\`\`

### Q2: [å¸¸è§é—®é¢˜2]

[é—®é¢˜æè¿°å’Œè§£å†³æ–¹æ¡ˆ]

### Q3: [å¸¸è§é—®é¢˜3]

[é—®é¢˜æè¿°å’Œè§£å†³æ–¹æ¡ˆ]

---

## ç¯å¢ƒç®¡ç†

### å¸¸ç”¨å‘½ä»¤

\`\`\`bash
# æ¿€æ´»ç¯å¢ƒ
conda activate [ç¯å¢ƒåç§°]

# é€€å‡ºç¯å¢ƒ
conda deactivate

# æŸ¥çœ‹å·²å®‰è£…çš„åŒ…
conda list

# åˆ é™¤ç¯å¢ƒ
conda remove -n [ç¯å¢ƒåç§°] --all
\`\`\`

---

## ä¸‹ä¸€æ­¥

ç¯å¢ƒé…ç½®å®Œæˆåï¼Œè¯·é˜…è¯» **[ä½¿ç”¨æŒ‡å—.md](ä½¿ç”¨æŒ‡å—.md)** äº†è§£å¦‚ä½•ä½¿ç”¨æœ¬é¡¹ç›®ã€‚

---

**å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒ**ï¼š
- ä½¿ç”¨æŒ‡å—ä¸­çš„"å¸¸è§é—®é¢˜"ç« èŠ‚
- é¡¹ç›®README.md
- [å…¶ä»–æ”¯æŒæ¸ é“]
\`\`\`

---

## æ¨¡æ¿ä¸‰ï¼šä½¿ç”¨æŒ‡å—.md

```markdown
# [é¡¹ç›®åç§°] - ä½¿ç”¨æŒ‡å—

> å®Œæ•´çš„é¡¹ç›®ä½¿ç”¨è¯´æ˜

## ğŸ“– å¦‚ä½•é˜…è¯»æœ¬æ–‡æ¡£

**æ ¹æ®æ‚¨çš„ç»éªŒæ°´å¹³é€‰æ‹©é˜…è¯»è·¯å¾„ï¼š**

### ğŸš€ å¿«é€Ÿä¸Šæ‰‹ï¼ˆ5åˆ†é’Ÿï¼‰
1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [æ ¸å¿ƒå‘½ä»¤é€ŸæŸ¥](#æ ¸å¿ƒå‘½ä»¤é€ŸæŸ¥)

### ğŸ“š å®Œæ•´å­¦ä¹ ï¼ˆé€‚åˆåˆå­¦è€…ï¼‰
1. [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
2. [è¯¦ç»†ä½¿ç”¨æ•™ç¨‹](#è¯¦ç»†ä½¿ç”¨æ•™ç¨‹)
3. [è¾“å‡ºç»“æœè§£è¯»](#è¾“å‡ºç»“æœè§£è¯»)
4. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

### ğŸ”§ å¼€å‘å®šåˆ¶ï¼ˆé€‚åˆå¼€å‘è€…ï¼‰
1. [é¡¹ç›®æ¶æ„è§£æ](#é¡¹ç›®æ¶æ„è§£æ)
2. [å‚æ•°é…ç½®è¯¦è§£](#å‚æ•°é…ç½®è¯¦è§£)
3. [å¼€å‘è€…æŒ‡å—](#å¼€å‘è€…æŒ‡å—)

---

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ ¸å¿ƒå‘½ä»¤é€ŸæŸ¥](#æ ¸å¿ƒå‘½ä»¤é€ŸæŸ¥)
- [è¯¦ç»†ä½¿ç”¨æ•™ç¨‹](#è¯¦ç»†ä½¿ç”¨æ•™ç¨‹)
- [è¾“å‡ºç»“æœè§£è¯»](#è¾“å‡ºç»“æœè§£è¯»)
- [é¡¹ç›®æ¶æ„è§£æ](#é¡¹ç›®æ¶æ„è§£æ)
- [å‚æ•°é…ç½®è¯¦è§£](#å‚æ•°é…ç½®è¯¦è§£)
- [å¼€å‘è€…æŒ‡å—](#å¼€å‘è€…æŒ‡å—)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [æ€§èƒ½ä¼˜åŒ–å»ºè®®](#æ€§èƒ½ä¼˜åŒ–å»ºè®®)

---

## é¡¹ç›®ç®€ä»‹

### é¡¹ç›®èƒŒæ™¯

[è¯¦ç»†æè¿°é¡¹ç›®èƒŒæ™¯ã€è¦è§£å†³çš„é—®é¢˜ã€åº”ç”¨åœºæ™¯ç­‰]

### æŠ€æœ¯ç‰¹ç‚¹

- **[ç‰¹ç‚¹1]**ï¼š[è¯¦ç»†è¯´æ˜]
- **[ç‰¹ç‚¹2]**ï¼š[è¯¦ç»†è¯´æ˜]
- **[ç‰¹ç‚¹3]**ï¼š[è¯¦ç»†è¯´æ˜]

### é€‚ç”¨åœºæ™¯

- âœ… [åœºæ™¯1]
- âœ… [åœºæ™¯2]
- âœ… [åœºæ™¯3]

### å‰ç½®è¦æ±‚

**å¿…é¡»**ï¼š
- å·²å®Œæˆç¯å¢ƒé…ç½®ï¼ˆå‚è§[ç¯å¢ƒé…ç½®.md](ç¯å¢ƒé…ç½®.md)ï¼‰
- [å…¶ä»–å¿…éœ€çš„å‰ç½®æ¡ä»¶]

**æ¨è**ï¼ˆéå¿…é¡»ï¼‰ï¼š
- [æ¨èä½†éå¿…éœ€çš„èƒŒæ™¯çŸ¥è¯†]

---

## å¿«é€Ÿå¼€å§‹

### ä¸‰æ­¥å¯åŠ¨æµç¨‹

\`\`\`bash
# æ­¥éª¤1ï¼šæ¿€æ´»ç¯å¢ƒ
conda activate [ç¯å¢ƒåç§°]

# æ­¥éª¤2ï¼šè¿›å…¥é¡¹ç›®ç›®å½•
cd "[é¡¹ç›®è·¯å¾„]"

# æ­¥éª¤3ï¼šè¿è¡Œå¿«é€Ÿæµ‹è¯•
python quick_start.py
\`\`\`

### å®Œæ•´å·¥ä½œæµ

\`\`\`bash
# 1. å¿«é€Ÿæµ‹è¯•
python quick_start.py

# 2. [å‡†å¤‡æ•°æ® - å¦‚æœéœ€è¦]
python prepare_data.py

# 3. è®­ç»ƒæ¨¡å‹
python train.py

# 4. ä½¿ç”¨æ¨¡å‹
python predict.py
\`\`\`

---

## æ ¸å¿ƒå‘½ä»¤é€ŸæŸ¥

### åŸºç¡€æ“ä½œ

\`\`\`bash
# ç¯å¢ƒæ¿€æ´»
conda activate [ç¯å¢ƒåç§°]

# å¿«é€Ÿæµ‹è¯•
python quick_start.py

# è®­ç»ƒæ¨¡å‹
python train.py

# é¢„æµ‹
python predict.py

# [å…¶ä»–å¸¸ç”¨å‘½ä»¤]
\`\`\`

### é…ç½®æŸ¥çœ‹

\`\`\`python
# åœ¨Pythonä¸­æŸ¥çœ‹é…ç½®
import config
print(config.[é…ç½®åç§°])
\`\`\`

---

## è¯¦ç»†ä½¿ç”¨æ•™ç¨‹

### æ­¥éª¤1ï¼šå¿«é€Ÿæµ‹è¯•ç¨‹åº

**ç›®çš„**ï¼š[è¯´æ˜è¿™ä¸€æ­¥çš„ç›®çš„]

#### è¿è¡Œå‘½ä»¤

\`\`\`bash
python quick_start.py
\`\`\`

#### ç¨‹åºæµç¨‹

[æè¿°ç¨‹åºçš„æ‰§è¡Œæµç¨‹]

#### è¾“å‡ºç¤ºä¾‹

\`\`\`
[é¢„æœŸè¾“å‡ºç¤ºä¾‹]
\`\`\`

#### é‡ç‚¹è¯´æ˜

- **[å…³é”®ç‚¹1]**ï¼š[è¯´æ˜]
- **[å…³é”®ç‚¹2]**ï¼š[è¯´æ˜]

---

### æ­¥éª¤2ï¼š[æ•°æ®å‡†å¤‡/è®­ç»ƒæ¨¡å‹/ç­‰]

**ç›®çš„**ï¼š[è¯´æ˜è¿™ä¸€æ­¥çš„ç›®çš„]

#### è¿è¡Œå‘½ä»¤

\`\`\`bash
python [è„šæœ¬å].py
\`\`\`

#### è¯¦ç»†æµç¨‹

##### é˜¶æ®µ1ï¼š[é˜¶æ®µåç§°]

[è¯¦ç»†æè¿°]

##### é˜¶æ®µ2ï¼š[é˜¶æ®µåç§°]

[è¯¦ç»†æè¿°]

#### æ—¶é—´ä¼°ç®—

| é˜¶æ®µ | CPUæ—¶é—´ | GPUæ—¶é—´ |
|------|---------|---------|
| [é˜¶æ®µ1] | [X]åˆ†é’Ÿ | [X]åˆ†é’Ÿ |
| [é˜¶æ®µ2] | [X]åˆ†é’Ÿ | [X]åˆ†é’Ÿ |
| **æ€»è®¡** | **[X]åˆ†é’Ÿ** | **[X]åˆ†é’Ÿ** |

#### æ³¨æ„äº‹é¡¹

1. [æ³¨æ„äº‹é¡¹1]
2. [æ³¨æ„äº‹é¡¹2]

---

## è¾“å‡ºç»“æœè§£è¯»

### [æŒ‡æ ‡ç±»åˆ«1]

#### [æŒ‡æ ‡1]

**å®šä¹‰**ï¼š[æŒ‡æ ‡å®šä¹‰]

**è®¡ç®—å…¬å¼**ï¼š
$$[LaTeXå…¬å¼]$$

å¼ä¸­ï¼Œ[å˜é‡è¯´æ˜]ã€‚

**æ„ä¹‰**ï¼š
- [æŒ‡æ ‡å«ä¹‰]
- [æœŸæœ›å€¼èŒƒå›´]

#### [æŒ‡æ ‡2]

[åŒä¸Š]

### [æŒ‡æ ‡ç±»åˆ«2]

[åŒä¸Šç»“æ„]

---

## é¡¹ç›®æ¶æ„è§£æ

### ç›®å½•ç»“æ„è¯¦è§£

\`\`\`
[é¡¹ç›®æ ¹ç›®å½•]/
â”‚
â”œâ”€â”€ config.py                 # [æ–‡ä»¶è¯´æ˜]
â”œâ”€â”€ train.py                  # [æ–‡ä»¶è¯´æ˜]
â”œâ”€â”€ predict.py                # [æ–‡ä»¶è¯´æ˜]
â”‚
â”œâ”€â”€ models/                   # [æ¨¡å—è¯´æ˜]
â”‚   â”œâ”€â”€ [æ¨¡å‹æ–‡ä»¶1].py       # [æ–‡ä»¶è¯´æ˜]
â”‚   â””â”€â”€ [æ¨¡å‹æ–‡ä»¶2].py       # [æ–‡ä»¶è¯´æ˜]
â”‚
â”œâ”€â”€ data/                     # [æ¨¡å—è¯´æ˜]
â”‚   â””â”€â”€ [æ•°æ®å¤„ç†æ–‡ä»¶].py   # [æ–‡ä»¶è¯´æ˜]
â”‚
â”œâ”€â”€ utils/                    # [æ¨¡å—è¯´æ˜]
â”‚   â”œâ”€â”€ [å·¥å…·æ–‡ä»¶1].py       # [æ–‡ä»¶è¯´æ˜]
â”‚   â””â”€â”€ [å·¥å…·æ–‡ä»¶2].py       # [æ–‡ä»¶è¯´æ˜]
â”‚
â””â”€â”€ [å…¶ä»–ç›®å½•]/              # [æ¨¡å—è¯´æ˜]
\`\`\`

### æ•°æ®æµå‘

\`\`\`mermaid
graph TD
    A[è¾“å…¥æ•°æ®] --> B[æ•°æ®å¤„ç†]
    B --> C[æ¨¡å‹è®­ç»ƒ]
    C --> D[æ¨¡å‹ä¿å­˜]
    D --> E[æ¨¡å‹æ¨ç†]
    E --> F[è¾“å‡ºç»“æœ]
\`\`\`

### æ¨¡å‹æ¶æ„

#### [æ¨¡å‹åç§°]æ¶æ„

\`\`\`
[ç”¨æ–‡å­—æˆ–ASCIIå›¾æè¿°æ¨¡å‹æ¶æ„]

è¾“å…¥å±‚ â†’ [å±‚1] â†’ [å±‚2] â†’ ... â†’ è¾“å‡ºå±‚
\`\`\`

**ç‰¹ç‚¹**ï¼š
- [ç‰¹ç‚¹1]
- [ç‰¹ç‚¹2]

---

## å‚æ•°é…ç½®è¯¦è§£

æ‰€æœ‰é…ç½®å‚æ•°åœ¨\`config.py\`æ–‡ä»¶ä¸­é›†ä¸­ç®¡ç†ã€‚

### [é…ç½®ç±»åˆ«1]

\`\`\`python
# [é…ç½®è¯´æ˜]
[å‚æ•°å1] = [é»˜è®¤å€¼]  # [å‚æ•°è¯´æ˜]
[å‚æ•°å2] = [é»˜è®¤å€¼]  # [å‚æ•°è¯´æ˜]
\`\`\`

**ä¿®æ”¹å»ºè®®**ï¼š

| å‚æ•° | å¢å¤§æ•ˆæœ | å‡å°æ•ˆæœ | æ¨èå€¼ |
|------|----------|----------|--------|
| [å‚æ•°1] | [æ•ˆæœ] | [æ•ˆæœ] | [å€¼] |
| [å‚æ•°2] | [æ•ˆæœ] | [æ•ˆæœ] | [å€¼] |

### [é…ç½®ç±»åˆ«2]

[åŒä¸Šç»“æ„]

---

## å¼€å‘è€…æŒ‡å—

### å¦‚ä½•æ·»åŠ æ–°æ¨¡å‹

#### æ­¥éª¤1ï¼šåˆ›å»ºæ¨¡å‹æ–‡ä»¶

åœ¨\`models/\`ç›®å½•ä¸‹åˆ›å»ºæ–°æ–‡ä»¶ï¼š

\`\`\`python
"""
[æ¨¡å‹åç§°]
"""
import torch
import torch.nn as nn
import config

class [æ¨¡å‹ç±»å](nn.Module):
    def __init__(self, [å‚æ•°]):
        super([æ¨¡å‹ç±»å], self).__init__()
        
        # [æ¨¡å‹å±‚å®šä¹‰]
    
    def forward(self, x):
        # [å‰å‘ä¼ æ’­é€»è¾‘]
        return output
    
    def get_model_info(self):
        # [è¿”å›æ¨¡å‹ä¿¡æ¯]
        return {...}

def create_[æ¨¡å‹åç§°]_model():
    return [æ¨¡å‹ç±»å]([å‚æ•°])
\`\`\`

#### æ­¥éª¤2ï¼šæ·»åŠ é…ç½®

åœ¨\`config.py\`ä¸­æ·»åŠ ï¼š

\`\`\`python
# [æ¨¡å‹åç§°]é…ç½®
[æ¨¡å‹åç§°]_CONFIG = {
    '[å‚æ•°1]': [å€¼],
    '[å‚æ•°2]': [å€¼],
}
\`\`\`

#### æ­¥éª¤3ï¼šé›†æˆåˆ°è®­ç»ƒæµç¨‹

[è¯´æ˜å¦‚ä½•å°†æ–°æ¨¡å‹é›†æˆåˆ°è®­ç»ƒè„šæœ¬ä¸­]

### å¦‚ä½•ä½¿ç”¨è‡ªå·±çš„æ•°æ®

#### æ–¹æ³•1ï¼š[æ–¹æ³•åç§°]

[è¯¦ç»†æ­¥éª¤]

#### æ–¹æ³•2ï¼š[æ–¹æ³•åç§°]

[è¯¦ç»†æ­¥éª¤]

### ä»£ç æ‰©å±•ç¤ºä¾‹

#### ç¤ºä¾‹1ï¼š[æ‰©å±•åŠŸèƒ½1]

\`\`\`python
# [ä»£ç ç¤ºä¾‹]
\`\`\`

#### ç¤ºä¾‹2ï¼š[æ‰©å±•åŠŸèƒ½2]

\`\`\`python
# [ä»£ç ç¤ºä¾‹]
\`\`\`

---

## å¸¸è§é—®é¢˜

### è®­ç»ƒç›¸å…³

**Q1: [é—®é¢˜1]**

A: [è§£å†³æ–¹æ¡ˆ]

**Q2: [é—®é¢˜2]**

A: [è§£å†³æ–¹æ¡ˆ]

### é¢„æµ‹ç›¸å…³

**Q3: [é—®é¢˜3]**

A: [è§£å†³æ–¹æ¡ˆ]

### ç¯å¢ƒç›¸å…³

**Q4: [é—®é¢˜4]**

A: [è§£å†³æ–¹æ¡ˆ]

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### è®­ç»ƒä¼˜åŒ–

#### 1. [ä¼˜åŒ–æ–¹æ³•1]

[è¯¦ç»†è¯´æ˜]

\`\`\`python
# [ä»£ç ç¤ºä¾‹]
\`\`\`

**æ•ˆæœ**ï¼š[ä¼˜åŒ–æ•ˆæœ]

#### 2. [ä¼˜åŒ–æ–¹æ³•2]

[è¯¦ç»†è¯´æ˜]

### æ¨ç†ä¼˜åŒ–

#### 1. [ä¼˜åŒ–æ–¹æ³•1]

[è¯¦ç»†è¯´æ˜]

#### 2. [ä¼˜åŒ–æ–¹æ³•2]

[è¯¦ç»†è¯´æ˜]

---

## é™„å½•

### A. æœ¯è¯­è¡¨

| æœ¯è¯­ | è¯´æ˜ |
|------|------|
| **[æœ¯è¯­1]** | [è¯´æ˜] |
| **[æœ¯è¯­2]** | [è¯´æ˜] |

### B. å‚è€ƒèµ„æ–™

**[ç±»åˆ«1]**ï¼š
- [èµ„æ–™1]ï¼š[é“¾æ¥]
- [èµ„æ–™2]ï¼š[é“¾æ¥]

**[ç±»åˆ«2]**ï¼š
- [èµ„æ–™1]ï¼š[é“¾æ¥]
- [èµ„æ–™2]ï¼š[é“¾æ¥]

### C. é¡¹ç›®ä¿¡æ¯

- **ç‰ˆæœ¬**ï¼šv[ç‰ˆæœ¬å·]
- **æœ€åæ›´æ–°**ï¼š[æ—¥æœŸ]
- **Pythonç‰ˆæœ¬**ï¼š[ç‰ˆæœ¬èŒƒå›´]
- **ä¸»è¦ä¾èµ–**ï¼š[ä¾èµ–åˆ—è¡¨]

---

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰
\`\`\`

---

## é’ˆå¯¹ä¸åŒæ¨¡å‹ç±»å‹çš„é€‚é…è¯´æ˜

### Transformeré¡¹ç›®é€‚é…

**ç‰¹æ®Šé…ç½®éƒ¨åˆ†**ï¼š

1. **æ¨¡å‹æ¶æ„è¯´æ˜**ï¼š
```markdown
### Transformeræ¶æ„

\`\`\`
è¾“å…¥åµŒå…¥
    â†“
ä½ç½®ç¼–ç 
    â†“
ç¼–ç å™¨å±‚ Ã— N
    â”œâ”€ å¤šå¤´è‡ªæ³¨æ„åŠ›
    â”œâ”€ å‰é¦ˆç½‘ç»œ
    â””â”€ æ®‹å·®è¿æ¥ + LayerNorm
    â†“
è§£ç å™¨å±‚ Ã— N (å¦‚æœæœ‰)
    â”œâ”€ æ©ç å¤šå¤´è‡ªæ³¨æ„åŠ›
    â”œâ”€ ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›
    â”œâ”€ å‰é¦ˆç½‘ç»œ
    â””â”€ æ®‹å·®è¿æ¥ + LayerNorm
    â†“
è¾“å‡ºå±‚
\`\`\`

**å…³é”®å‚æ•°**ï¼š
- \`d_model\`: æ¨¡å‹ç»´åº¦ï¼ˆå¦‚512ï¼‰
- \`n_heads\`: æ³¨æ„åŠ›å¤´æ•°ï¼ˆå¦‚8ï¼‰
- \`n_layers\`: ç¼–ç å™¨/è§£ç å™¨å±‚æ•°ï¼ˆå¦‚6ï¼‰
- \`d_ff\`: å‰é¦ˆç½‘ç»œç»´åº¦ï¼ˆå¦‚2048ï¼‰
- \`dropout\`: Dropoutç‡ï¼ˆå¦‚0.1ï¼‰
```

2. **ç‰¹æ®Šé…ç½®é¡¹**ï¼š
```python
TRANSFORMER_CONFIG = {
    'd_model': 512,
    'n_heads': 8,
    'n_layers': 6,
    'd_ff': 2048,
    'dropout': 0.1,
    'max_seq_length': 512,
}
```

3. **æ•°æ®å¤„ç†**ï¼š
```markdown
### æ–‡æœ¬é¢„å¤„ç†

#### åˆ†è¯å™¨é…ç½®

\`\`\`python
from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')
\`\`\`

#### åºåˆ—å¡«å……

\`\`\`python
# å°†åºåˆ—å¡«å……æˆ–æˆªæ–­åˆ°å›ºå®šé•¿åº¦
padded_sequences = pad_sequences(sequences, maxlen=512, padding='post')
\`\`\`
```

---

### LSTM+CNNæ··åˆæ¨¡å‹é€‚é…

**ç‰¹æ®Šé…ç½®éƒ¨åˆ†**ï¼š

1. **æ¨¡å‹æ¶æ„è¯´æ˜**ï¼š
```markdown
### LSTM+CNNæ··åˆæ¶æ„

\`\`\`
è¾“å…¥åºåˆ—
    â†“
LSTMå±‚ï¼ˆåŒå‘ï¼‰
    â”œâ”€ å‰å‘LSTM
    â””â”€ åå‘LSTM
    â†“
æ‹¼æ¥
    â†“
1Då·ç§¯å±‚
    â”œâ”€ å·ç§¯æå–å±€éƒ¨ç‰¹å¾
    â”œâ”€ BatchNorm
    â””â”€ æ¿€æ´»å‡½æ•°
    â†“
æ± åŒ–å±‚
    â†“
å…¨è¿æ¥å±‚
    â†“
è¾“å‡º
\`\`\`

**ç‰¹ç‚¹**ï¼š
- LSTMæ•è·é•¿æœŸä¾èµ–
- CNNæå–å±€éƒ¨æ¨¡å¼
- ç»“åˆä¸¤è€…ä¼˜åŠ¿
```

2. **ç‰¹æ®Šé…ç½®é¡¹**ï¼š
```python
LSTMCNN_CONFIG = {
    'lstm_hidden': 128,
    'lstm_layers': 2,
    'bidirectional': True,
    'conv_channels': [64, 128],
    'kernel_sizes': [3, 5],
    'dropout': 0.5,
}
```

3. **æ—¶é—´åºåˆ—æ•°æ®å¤„ç†**ï¼š
```markdown
### æ—¶é—´åºåˆ—æ•°æ®å‡†å¤‡

#### æ»‘åŠ¨çª—å£

\`\`\`python
def create_sequences(data, seq_length):
    sequences = []
    for i in range(len(data) - seq_length):
        seq = data[i:i + seq_length]
        sequences.append(seq)
    return np.array(sequences)
\`\`\`

#### æ•°æ®å½’ä¸€åŒ–

\`\`\`python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
normalized_data = scaler.fit_transform(data)
\`\`\`
```

---

### Autoencoderé¡¹ç›®é€‚é…

**ç‰¹æ®Šé…ç½®éƒ¨åˆ†**ï¼š

1. **æ¨¡å‹æ¶æ„è¯´æ˜**ï¼š
```markdown
### Autoencoderæ¶æ„

\`\`\`
è¾“å…¥ (åŸå§‹ç»´åº¦)
    â†“
ç¼–ç å™¨
    â”œâ”€ çº¿æ€§å±‚1 + æ¿€æ´»
    â”œâ”€ çº¿æ€§å±‚2 + æ¿€æ´»
    â””â”€ ç“¶é¢ˆå±‚ï¼ˆæ½œåœ¨ç©ºé—´ï¼‰
    â†“
è§£ç å™¨
    â”œâ”€ çº¿æ€§å±‚1 + æ¿€æ´»
    â”œâ”€ çº¿æ€§å±‚2 + æ¿€æ´»
    â””â”€ è¾“å‡ºå±‚ï¼ˆé‡æ„ï¼‰
    â†“
è¾“å‡º (é‡æ„ç»´åº¦)
\`\`\`

**åº”ç”¨åœºæ™¯**ï¼š
- é™ç»´å¯è§†åŒ–
- å¼‚å¸¸æ£€æµ‹
- ç‰¹å¾å­¦ä¹ 
- æ•°æ®å»å™ª
```

2. **ç‰¹æ®Šé…ç½®é¡¹**ï¼š
```python
AUTOENCODER_CONFIG = {
    'input_dim': 1000,
    'hidden_dims': [512, 256, 128],
    'latent_dim': 64,
    'activation': 'relu',
    'dropout': 0.2,
}

# å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰é¢å¤–é…ç½®
VAE_CONFIG = {
    **AUTOENCODER_CONFIG,
    'kl_weight': 0.01,  # KLæ•£åº¦æƒé‡
}
```

3. **æŸå¤±å‡½æ•°**ï¼š
```markdown
### é‡æ„æŸå¤±

#### æ ‡å‡†Autoencoder

\`\`\`python
# MSEæŸå¤±
reconstruction_loss = nn.MSELoss()(reconstructed, original)
\`\`\`

#### å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰

\`\`\`python
# é‡æ„æŸå¤± + KLæ•£åº¦
recon_loss = nn.MSELoss()(reconstructed, original)
kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
total_loss = recon_loss + kl_weight * kl_loss
\`\`\`
```

4. **å¯è§†åŒ–æ½œåœ¨ç©ºé—´**ï¼š
```markdown
### æ½œåœ¨ç©ºé—´å¯è§†åŒ–

\`\`\`python
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# æå–æ½œåœ¨å‘é‡
latent_vectors = []
for data in dataloader:
    z = encoder(data)
    latent_vectors.append(z.detach().cpu().numpy())
latent_vectors = np.concatenate(latent_vectors)

# t-SNEé™ç»´
tsne = TSNE(n_components=2)
latent_2d = tsne.fit_transform(latent_vectors)

# ç»˜å›¾
plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=labels)
plt.colorbar()
plt.title('æ½œåœ¨ç©ºé—´åˆ†å¸ƒ')
plt.savefig('latent_space.png')
\`\`\`
```

---

## å¸¸ç”¨ä»£ç ç‰‡æ®µåº“

### æ•°æ®åŠ è½½

```python
# PyTorchæ•°æ®é›†ç±»æ¨¡æ¿
class CustomDataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        sample = self.data[idx]
        label = self.labels[idx]
        
        if self.transform:
            sample = self.transform(sample)
        
        return sample, label
```

### è®­ç»ƒå¾ªç¯

```python
# æ ‡å‡†è®­ç»ƒå¾ªç¯æ¨¡æ¿
def train_epoch(model, train_loader, optimizer, criterion, device):
    model.train()
    total_loss = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    return total_loss / len(train_loader)
```

### è¯„ä¼°

```python
# è¯„ä¼°å‡½æ•°æ¨¡æ¿
def evaluate(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            pred = output.argmax(dim=1)
            correct += (pred == target).sum().item()
            total += target.size(0)
    
    accuracy = correct / total
    return accuracy
```

### æ¨¡å‹ä¿å­˜å’ŒåŠ è½½

```python
# ä¿å­˜æ¨¡å‹
def save_model(model, optimizer, epoch, path):
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
    }, path)

# åŠ è½½æ¨¡å‹
def load_model(model, optimizer, path, device):
    checkpoint = torch.load(path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    epoch = checkpoint['epoch']
    return epoch
```

---

## æ–‡æ¡£ç»´æŠ¤æŒ‡å—

### ç‰ˆæœ¬æ›´æ–°

æ¯æ¬¡æ›´æ–°æ–‡æ¡£æ—¶ï¼š
1. æ›´æ–°æ–‡æ¡£åº•éƒ¨çš„ç‰ˆæœ¬å·
2. æ›´æ–°"æœ€åæ›´æ–°"æ—¥æœŸ
3. åœ¨CHANGELOG.mdä¸­è®°å½•å˜æ›´

### æ–‡æ¡£æ£€æŸ¥æ¸…å•

å‘å¸ƒå‰æ£€æŸ¥ï¼š
- [ ] æ‰€æœ‰å ä½ç¬¦å·²æ›¿æ¢
- [ ] ä»£ç ç¤ºä¾‹å·²æµ‹è¯•
- [ ] é“¾æ¥æ­£ç¡®å¯è®¿é—®
- [ ] æ ¼å¼ç»Ÿä¸€è§„èŒƒ
- [ ] æ‹¼å†™æ£€æŸ¥é€šè¿‡
- [ ] ç¤ºä¾‹è¾“å‡ºä¸å®é™…ä¸€è‡´

### å¸¸è§é—®é¢˜æ”¶é›†

å®šæœŸæ”¶é›†ç”¨æˆ·åé¦ˆï¼š
1. è®°å½•å¸¸è§é—®é¢˜
2. æ›´æ–°"å¸¸è§é—®é¢˜"ç« èŠ‚
3. ä¼˜åŒ–ä¸æ¸…æ™°çš„è¯´æ˜

---

## æ€»ç»“

æœ¬æ¨¡æ¿æä¾›äº†å®Œæ•´çš„æ·±åº¦å­¦ä¹ é¡¹ç›®æ–‡æ¡£æ¡†æ¶ï¼Œæ¶µç›–ï¼š
- **README.md**ï¼šé¡¹ç›®æ¦‚è§ˆå’Œå¿«é€Ÿå¼€å§‹
- **ç¯å¢ƒé…ç½®.md**ï¼šè¯¦ç»†çš„ç¯å¢ƒæ­å»ºæŒ‡å—
- **ä½¿ç”¨æŒ‡å—.md**ï¼šå®Œæ•´çš„ä½¿ç”¨æ–‡æ¡£

æ ¹æ®ä½ çš„é¡¹ç›®ç‰¹ç‚¹ï¼š
- é€‰æ‹©åˆé€‚çš„ç« èŠ‚
- å¡«å†™å ä½ç¬¦å†…å®¹
- å‚è€ƒæ¨¡å‹ç‰¹å®šçš„é€‚é…ç¤ºä¾‹
- ä½¿ç”¨ä»£ç ç‰‡æ®µåº“

**ä½¿ç”¨æç¤º**ï¼š
1. ä»æ¨¡æ¿å¤åˆ¶å†…å®¹åˆ°ä½ çš„é¡¹ç›®
2. æ›¿æ¢æ‰€æœ‰`[å ä½ç¬¦]`
3. åˆ é™¤ä¸éœ€è¦çš„éƒ¨åˆ†
4. æ·»åŠ é¡¹ç›®ç‰¹æœ‰çš„å†…å®¹
5. ä¿æŒæ–‡æ¡£ä¸ä»£ç åŒæ­¥æ›´æ–°

ç¥æ‚¨æ’°å†™å‡ºä¼˜è´¨çš„é¡¹ç›®æ–‡æ¡£ï¼ ğŸ“š

